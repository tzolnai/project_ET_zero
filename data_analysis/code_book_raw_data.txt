This text file contains information about the data files, which are generated by the experiment script.

1. ASRT task raw data
    Files like: subject_10__log.csv
    Overview:
    These files contains all eye-tracking data samples recorded during the ASRT task part of the experiment. The subject ID is in the file name: subject_X__log, where
    X is the subject ID. One line of this file means one sample what the eye-tracking device returned.

    Fields:
    - computer_name: Internally used identifier of the computer we used for the experiment. We used only one computer, so this field has no actual effect.

    - monitor_width_pixel: Monitor's with in pixel unit (e.g. 1920).

    - monitor_height_pixel: Monitor's height in pixel unit (e.g. 1080).

    - subject_group: We did not have different groups in this experiment, so this field is always empty.

    - subject_number: ID of the subject, which belongs to this data file. It should be the same what the file name contains.

    - subject_sex: Sex of the subject. Three possible values: male, female, other.

    - subject_age: Age of the subject (e.g. 22).

    - asrt_type: Type of ASRT task of the given epoch. Imlicit-explicit difference means a difference in the instructions.
      Possible values: noASRT - randomized data, implicit - implicit ASRT, explicit - explicit ASRT (explicit instruction).
      In the first epoch of the experiment we used randomized trials, so there the ASRT type is noASRT, otherwise it's implicit.
      We did not used explicit instructions in this experiment.

    - PCode: The sequence we used to generate the trials according to ASRT design.
      Possible values: noPattern - randomized data, 1234, 1243, 1324, 1342, 1423 or 1432 - sequences of stimulus positons.
      1234 means the stimulus is first displayed at the 1st position, then it is displayed at the 2nd positon after a random trial, etc.

    - session: Number of sessions. Here, session means one part of data acqusition, which was done at once, without any break. There were two sessions
      of the ASRT task: Learning phase (session 1) and Testing phase (session 2).

    - epoch: Number of the current epoch. A number in [1-8] interval. Learning phase contains the first 5 epochs (1-5 epochs), while testing phase
      contains three additional epochs (6-8 epochs). This epoch number is a global number apply to the whole experiment.

    - block: Number of the block. A number in [1-40] interval. Learning phase contains the first 5 * 5 blocks (1-25 blocks), while testing phase
      contains 3 * 5 additional block (25-40 blocks). This block number is a global number apply to the whole experiment.

    - trial: Number of the trial inside the given block. A number in [1-82] interval. This not a global number, it can be interpreted together
      with the block number.

    - RSI_time: This variable meant to measure the actual RSI time of the given trial. It can't be used reliably, so we did't actually use this
      variable for anything.

    - frame_rate: Monitor's refresh rate measured by Psychopy's getActualFrameRate() method. It's a value in FPS (frame per second) and it tells how many
      frames were displayed during one second. It was measured once at the beginning of the experiment.

    - frame_time: Monitor's avarage frame time measured by Psychopy's getMsPerFrame() method. It's a value in ms (millisecond) and it tells how much
      time it takes to display one frame on the screen. It was measured once at the beginning of the experiment.

    - frame_sd: Standard deviation of the monitor's frame time measured by Psychopy's getMsPerFrame() method. It's a value in ms (millisecond)
      and it indicates the deviation in displaying one frame on the screen. It was measured once at the beginning of the experiment.

    - stimulus_color: The color used for displaying the stimulus on the screen. It's one of PsychoPy predefined color names. We used "DarkBlue" during
      the whole experiment.

    - trial_type_pr: This field indicates whether the stimulus of the current trial was generated randomly ("random") or it was generated as part of
      of the given sequence ("pattern"). In the first epoch, where all trials were generated randomly, this field is always "random",
      while in other epochs, this field follows the ASRT alternating structure, so "random" and "pattern" values are alternating.

    - triplet_type_hl: It's an attribute of three trials, not only one. The value put in the line of a trial means a property of the last three trials.
      So for the first two trials of all block this field contains a "none" value. Otherwise this field can be "low" or "high". "low" means
      low probability triplet and "high" means high probability triplet. This probabilities should be interpreted according to the given epoch.
      In the learning epochs this probability are calculeted according to the learning sequence, while in the interference epoch (epoch 7), this is computed
      based on the interference sequence. It's alway calculated based on the sequence of the given epoch (see PCode field). In the first epoch,
      where there were no sequence, this field has always "none" value.

    - stimulus: The place, where the stimulus was showed in the given trial. It's value in [1-4] interval. 1 - top-left positon, 2 - top-right positon,
      3 - bottom-left position, 4 - bottom-right position.

    - trial_phase: This variable has three possible values: before_stimulus, stimulus_on_screen, after_reaction. We have these three states of the
      given trial. before_stimulus means the response-to-stimulus interval, where the stimulus is not on the screen yet. stimulus_on_screen indicates
      the state where the stimulus is displayed on the screen. after_reaction is used for technical reasons. We are in this state when the software
      already registered a response, but did not hide the stimulus yet (e.g. there is a frame rate, which delays updating the screen). Reaction time
      should be calculated based on the eye-tracking data in the stimulus_on_screen state.

    - left_gaze_data_X_ADCS: X coordinate of the gaze data registered for the left eye. This value can be interpreted inside Active Display Coordinate System.
      https://developer.tobiipro.com/commonconcepts/coordinatesystems.html

    - left_gaze_data_Y_ADCS: Y coordinate of the gaze data registered for the left eye. This value can be interpreted inside Active Display Coordinate System.
      https://developer.tobiipro.com/commonconcepts/coordinatesystems.html

    - right_gaze_data_X_ADCS: X coordinate of the gaze data registered for the right eye. This value can be interpreted inside Active Display Coordinate System.
      https://developer.tobiipro.com/commonconcepts/coordinatesystems.html

    - right_gaze_data_Y_ADCS: Y coordinate of the gaze data registered for the right eye. This value can be interpreted inside Active Display Coordinate System.
      https://developer.tobiipro.com/commonconcepts/coordinatesystems.html

    - left_gaze_data_X_PCMCS: X coordinate of the gaze data registered for the left eye. This value can be interpreted inside PsychoPy's coordinate system with cm unit.
      https://www.psychopy.org/general/units.html

    - left_gaze_data_Y_PCMCS: Y coordinate of the gaze data registered for the left eye. This value can be interpreted inside PsychoPy's coordinate system with cm unit.
      https://www.psychopy.org/general/units.html

    - right_gaze_data_X_PCMCS: X coordinate of the gaze data registered for the right eye. This value can be interpreted inside PsychoPy's coordinate system with cm unit.
      https://www.psychopy.org/general/units.html

    - right_gaze_data_Y_PCMCS: Y coordinate of the gaze data registered for the right eye. This value can be interpreted inside PsychoPy's coordinate system with cm unit.
      https://www.psychopy.org/general/units.html

    - left_eye_distance: Distance of the left eye from the screen. The unit here is millimeter.

    - right_eye_distance: Distance of the right eye from the screen. The unit here is millimeter.

    - left_gaze_validity: This is a bool value which tells us whether the eye-tracker could give a valid gaze data for the left eye. We can use left eye data, when this variable is true.

    - right_gaze_validity: This is a bool value which tells us whether the eye-tracker could give a valid gaze data for the right eye. We can use right eye data, when this variable is true.

    - left_pupil_diameter: Pupil diameter in millimeter of the left eye.

    - right_pupil_diameter: Pupil diameter in millimeter of the right eye.

    - left_pupil_validity: This is a bool value which tells us whether the eye-tracker could give a valid pupil data for the left eye. We can use left eye pupil data, when this variable is true.

    - right_pupil_validity: This is a bool value which tells us whether the eye-tracker could give a valid pupil data for the right eye. We can use right eye pupil data, when this variable is true.

    - gaze_data_time_stamp: A timestamp for the given sample. We can use this information to calculate reaction times with selecting the first sample, when the stimulus is disaplyed and first sample
      where the response was recorded and compare these samples' timestamp.

    - stimulus_1_position_X_PCMCS: X coordinate of the first stimulus on screen using PsychoPy's coordinate system with cm unit.
      https://www.psychopy.org/general/units.html

    - stimulus_1_position_Y_PCMCS: Y coordinate of the first stimulus on screen using PsychoPy's coordinate system with cm unit.
      https://www.psychopy.org/general/units.html

    - stimulus_2_position_X_PCMCS: X coordinate of the second stimulus on screen using PsychoPy's coordinate system with cm unit.
      https://www.psychopy.org/general/units.html

    - stimulus_2_position_Y_PCMCS: Y coordinate of the second stimulus on screen using PsychoPy's coordinate system with cm unit.
      https://www.psychopy.org/general/units.html

    - stimulus_3_position_X_PCMCS: X coordinate of the third stimulus on screen using PsychoPy's coordinate system with cm unit.
      https://www.psychopy.org/general/units.html

    - stimulus_3_position_Y_PCMCS: Y coordinate of the third stimulus on screen using PsychoPy's coordinate system with cm unit.
      https://www.psychopy.org/general/units.html

    - stimulus_4_position_X_PCMCS: X coordinate of the fourth stimulus on screen using PsychoPy's coordinate system with cm unit.
      https://www.psychopy.org/general/units.html

    - stimulus_4_position_Y_PCMCS: Y coordinate of the fourth stimulus on screen using PsychoPy's coordinate system with cm unit.
      https://www.psychopy.org/general/units.html

    - quit_log: This variable codes whether happened any unexpected quit during a sessions. This should have happened rarely.
      This variable has two values: sessionend_planned_quit or userquit. userquit means the session was interrupted and it was
      continued later. sessionend_planned_quit means the sessions was run without any interruption.

2. Jacobi PDP test raw data (generated responses)
    Files like: subject_10__jacobi_log.csv
    Overview:
    These files contains the generated responses during the PDP task both in inclusion and exclusion phase. The subject ID is in the file name: subject_X__jacobi_log, where
    X is the subject ID. One line of this file means one recorded response of the subject.

    Fields:
    - computer_name: Internally used identifier of the computer we used for the experiment. We used only one computer, so this field has no actual effect.

    - monitor_width_pixel: Monitor's with in pixel unit (e.g. 1920).

    - monitor_height_pixel: Monitor's height in pixel unit (e.g. 1080).

    - subject_group: We did not have different groups in this experiment, so this field is always empty.

    - subject_number: ID of the subject, which belongs to this data file. It should be the same what the file name contains.

    - subject_sex: Sex of the subject. Three possible values: male, female, other.

    - subject_age: Age of the subject (e.g. 22).

    - asrt_type: Type of ASRT task of the given epoch. Imlicit-explicit difference means a difference in the instructions.
      Possible values: noASRT - randomized data, implicit - implicit ASRT, explicit - explicit ASRT (explicit instruction).
      In the first epoch of the experiment we used randomized trials, so there the ASRT type is noASRT, otherwise it's implicit.
      We did not used explicit instructions in this experiment.

    - PCode: The sequence we used to generate the trials according to ASRT design.
      Possible values: noPattern - randomized data, 1234, 1243, 1324, 1342, 1423 or 1432 - sequences of stimulus positons.
      1234 means the stimulus is first displayed at the 1st position, then it is displayed at the 2nd positon after a random trial, etc.

    - test_type: This variable indicated, whether which phase of the PDP task we are in: inclusion or exclusion.

    - run: The serial number of the current run. A number in [1,4] interval. Both phases, inclusion and exclusion had four runs.

    - trial: The serial number of the current trial. A number in [1,24] interval. All runs contains 24 trials.

    - frame_rate: Monitor's refresh rate measured by Psychopy's getActualFrameRate() method. It's a value in FPS (frame per second) and it tells how many
      frames were displayed during one second. It was measured once at the beginning of the experiment.

    - frame_time: Monitor's avarage frame time measured by Psychopy's getMsPerFrame() method. It's a value in ms (millisecond) and it tells how much
      time it takes to display one frame on the screen. It was measured once at the beginning of the experiment.

    - frame_sd: Standard deviation of the monitor's frame time measured by Psychopy's getMsPerFrame() method. It's a value in ms (millisecond)
      and it indicates the deviation in displaying one frame on the screen. It was measured once at the beginning of the experiment.

    - response: The recorded response in the given trial. A response means a fixation on one of the given stimulus positions selected by the subject.
      This variable is a number in [1, 4] interval. This stimulus identifier should be interpreted the same as in the ASRT task output files.
